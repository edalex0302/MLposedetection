import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
import joblib  # For saving/loading the model
import cv2
import mediapipe as mp

# Load the CSV with pose landmarks
data = pd.read_csv('MEDIAPIPE/landmarks4_v1.csv')

# Split features (X) and labels (y)
X = data.drop('class', axis=1)  # All columns except 'class' are features
y = data['class']  # 'class' column is the target label

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest classifier
classifier = RandomForestClassifier()
classifier.fit(X_train, y_train)

# Save the trained model to a file
joblib.dump(classifier, 'random_forest_pose_model.joblib')
print("Model saved to 'random_forest_pose_model.joblib'")

# Test the classifier
y_pred = classifier.predict(X_test)

# Print classification report to evaluate performance
print(classification_report(y_test, y_pred))

# Setup webcam feed
cap = cv2.VideoCapture(0)
mp_pose = mp.solutions.pose

with mp_pose.Pose(static_image_mode=False) as pose:
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # Convert the image to RGB and process it
        results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

        # Extract landmarks for real-time pose classification
        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            keypoints = [(lm.x, lm.y) for lm in landmarks]
            
            # Make sure to format keypoints into the same format as the training data
            pose_data = [keypoint for pair in keypoints for keypoint in pair]
            prediction = classifier.predict([pose_data])
            
            # Display the prediction on the webcam feed
            cv2.putText(frame, f"Pose: {prediction[0]}", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)

        if results.pose_landmarks:
            mp.solutions.drawing_utils.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        # Show the webcam feed
        cv2.imshow('Pose Detection', frame)

        if cv2.waitKey(5) & 0xFF == ord('q'):
            break

cap.release()
cv2.destroyAllWindows()

# Print classification report to evaluate performance
print(classification_report(y_test, y_pred))
